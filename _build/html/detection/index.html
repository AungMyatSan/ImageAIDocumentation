

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Detection Classes &mdash; ImageAI 2.1.5 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Video and Live-Feed Detection and Analysis" href="../video/index.html" />
    <link rel="prev" title="Prediction Classes" href="../prediction/index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> ImageAI
          

          
          </a>

          
            
            
              <div class="version">
                3.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../prediction/index.html">Prediction Classes</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Detection Classes</a><ul class="simple">
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../video/index.html">Video and Live-Feed Detection and Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../custom/index.html">Custom Training: Prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../customdetection/index.html">Custom Object Detection: Training and Inference</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ImageAI</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Detection Classes</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/detection/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="detection-classes">
<h1>Detection Classes<a class="headerlink" href="#detection-classes" title="Permalink to this headline">¶</a></h1>
<div class="figure align-default">
<img alt="../_images/image1.jpg" src="../_images/image1.jpg" />
</div>
<p><strong>ImageAI</strong> provides very powerful yet easy to use classes and functions to perform <strong>Image Object Detection and Extraction</strong>.</p>
<p><strong>ImageAI</strong> allows you to perform all of these with state-of-the-art deep learning algorithms like <strong>RetinaNet</strong>, <strong>YOLOv3</strong> and <strong>TinyYOLOv3</strong>. With <strong>ImageAI</strong> you can run detection tasks and analyse images.</p>
<p>Find below the classes and their respective functions available for you to use.
These classes can be integrated into any traditional python program you are developing, be it a website, Windows/Linux/MacOS application or a system
that supports or part of a Local-Area-Network.</p>
<p><strong>======= imageai.Detection.ObjectDetection =======</strong></p>
<p>This <strong>ObjectDetection</strong> class provides you function to perform object detection on any image or set of images, using <strong>pre-trained</strong> models that was trained on
the <strong>COCO</strong> dataset. The models supported are <strong>RetinaNet</strong>, <strong>YOLOv3</strong> and <strong>TinyYOLOv3</strong>. This means you can detect and recognize 80 different kind of
common everyday objects. To get started, download any of the pre-trained model that you want to use via the links below.</p>
<p><a class="reference external" href="https://github.com/OlafenwaMoses/ImageAI/releases/tag/1.0/">Download RetinaNet Model - resnet50_coco_best_v2.0.1.h5</a></p>
<p><a class="reference external" href="https://github.com/OlafenwaMoses/ImageAI/releases/tag/1.0/">Download YOLOv3 Model - yolo.h5</a></p>
<p><a class="reference external" href="https://github.com/OlafenwaMoses/ImageAI/releases/tag/1.0/">Download TinyYOLOv3 Model - yolo-tiny.h5</a></p>
<p>Once you have downloaded the model of your choice, you should create a new instance of the <strong>ObjectDetection</strong> class as seen in the sample below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">imageai.Detection</span> <span class="kn">import</span> <span class="n">ObjectDetection</span>

<span class="n">detector</span> <span class="o">=</span> <span class="n">ObjectDetection</span><span class="p">()</span>
</pre></div>
</div>
<p>Once you have created an instance of the class, you can use the functions below to set your instance property and start detecting objects in images.</p>
<ul>
<li><p><strong>.setModelTypeAsRetinaNet()</strong> , This function sets the model type of the object detection instance you created to the <strong>RetinaNet</strong> model, which means you will be performing your object detection tasks using the pre-trained “RetinaNet” model you downloaded from the links above.  Find example code below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">detector</span><span class="o">.</span><span class="n">setModelTypeAsRetinaNet</span><span class="p">()</span>
</pre></div>
</div>
</li>
<li><p><strong>.setModelTypeAsYOLOv3()</strong> , This function sets the model type of the object detection instance you created to the <strong>YOLOv3</strong> model, which means you will be performing your object detection tasks using the pre-trained “YOLOv3” model you downloaded from the links above.  Find example code below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">detector</span><span class="o">.</span><span class="n">setModelTypeAsYOLOv3</span><span class="p">()</span>
</pre></div>
</div>
</li>
<li><p><strong>.setModelTypeAsTinyYOLOv3()</strong> , This function sets the model type of the object detection instance you created to the <strong>TinyYOLOv3</strong> model, which means you will be performing your object detection tasks using the pre-trained “TinyYOLOv3” model you downloaded from the links above.  Find example code below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">detector</span><span class="o">.</span><span class="n">setModelTypeAsTinyYOLOv3</span><span class="p">()</span>
</pre></div>
</div>
</li>
<li><p><strong>.setModelPath()</strong> , This function accepts a string which must be the path to the model file you downloaded and must corresponds to the model type you set for your object detection instance. Find example code,and parameters of the function below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">detector</span><span class="o">.</span><span class="n">setModelPath</span><span class="p">(</span><span class="s2">&quot;yolo.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
<blockquote>
<div><p>– <em>parameter</em> <strong>model_path</strong> (required) : This is the path to your downloaded model file.</p>
</div></blockquote>
<ul>
<li><p><strong>.loadModel()</strong> , This function loads the model from the path you specified in the function call above into your object detection instance. Find example code below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">detector</span><span class="o">.</span><span class="n">loadModel</span><span class="p">()</span>
</pre></div>
</div>
</li>
</ul>
<blockquote>
<div><p>– <em>parameter</em> <strong>detection_speed</strong> (optional) : This parameter allows you to reduce the time it takes to detect objects in an image by up to 80% which leads to slight reduction in accuracy. This parameter accepts string values. The available values are “normal”, “fast”, “faster”, “fastest” and “flash”. The default values is “normal”</p>
</div></blockquote>
<ul>
<li><p><strong>.detectObjectsFromImage()</strong> , This is the function that performs object detection task after the model as loaded. It can be called many times to detect objects in any number of images. Find example code below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">detections</span> <span class="o">=</span> <span class="n">detector</span><span class="o">.</span><span class="n">detectObjectsFromImage</span><span class="p">(</span><span class="n">input_image</span><span class="o">=</span><span class="s2">&quot;image.jpg&quot;</span><span class="p">,</span> <span class="n">output_image_path</span><span class="o">=</span><span class="s2">&quot;imagenew.jpg&quot;</span><span class="p">,</span> <span class="n">minimum_percentage_probability</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
<blockquote>
<div><p>– <em>parameter</em> <strong>input_image</strong> (required) : This refers to the path to image file which you want to detect. You can set this parameter to the Numpy array of File stream of any image if you set the paramter <strong>input_type</strong> to “array” or “stream”</p>
<p class="attribution">—<em>parameter</em> <strong>output_image_path</strong> (required only if <strong>input_type</strong> = “file” ) :  This refers to the file path to which the detected image will be saved. It is required only if <strong>input_type</strong> = “file”</p>
</div></blockquote>
<blockquote>
<div><p>– <em>parameter</em> <strong>minimum_percentage_probability</strong> (optional ) :  This parameter is used to determine the integrity of the detection results. Lowering the value shows more objects while increasing the value ensures objects with the highest accuracy are detected. The default value is 50.</p>
<p class="attribution">—<em>parameter</em> <strong>output_type</strong> (optional ) :  This parameter is used to set the format in which the detected image will be produced. The available values are “file” and “array”. The default value is “file”. If this parameter is set to “array”, the function will return a Numpy array of the detected image. See sample below::</p>
</div></blockquote>
<blockquote>
<div><blockquote>
<div><p>returned_image, detections = detector.detectObjectsFromImage(input_image=”image.jpg”, output_type=”array”, minimum_percentage_probability=30)</p>
</div></blockquote>
<p class="attribution">—<em>parameter</em> <strong>display_percentage_probability</strong> (optional ) :  This parameter can be used to hide the percentage probability of each object detected in the detected image if set to False. The default values is True.</p>
</div></blockquote>
<blockquote>
<div><p>– <em>parameter</em> <strong>display_object_name</strong> (optional ) :  This parameter can be used to hide the name of each object detected in the detected image if set to False. The default values is True.</p>
<p class="attribution">—<em>parameter</em> <strong>extract_detected_objects</strong> (optional ) :  This parameter can be used to extract and save/return each object detected in an image as a seperate image. The default values is False.</p>
</div></blockquote>
<blockquote>
<div><p>– <em>parameter</em> <strong>thread_safe</strong> (optional) : This ensures the loaded detection model works across all threads if set to true.</p>
<p class="attribution">—<em>returns</em> :  The returned values will depend on the parameters parsed into the <strong>detectObjectsFromImage()</strong> function. See the comments and code below</p>
</div></blockquote>
<blockquote>
<div><blockquote>
<div><dl class="simple">
<dt>“””</dt><dd><p>If all required parameters are set and ‘output_image_path’ is set to a file path you want the detected image to be saved, the function will return:</p>
<ol class="arabic simple">
<li><dl class="simple">
<dt>an array of dictionaries, with each dictionary corresponding to the objects</dt><dd><dl class="simple">
<dt>detected in the image. Each dictionary contains the following property:</dt><dd><ul class="simple">
<li><p>name (string)</p></li>
<li><p>percentage_probability (float)</p></li>
<li><p>box_points (tuple of x1,y1,x2 and y2 coordinates)</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</li>
</ol>
</dd>
</dl>
<p>“””
detections = detector.detectObjectsFromImage(input_image=”image.jpg”, output_image_path=”imagenew.jpg”, minimum_percentage_probability=30)</p>
<dl class="simple">
<dt>“””</dt><dd><p>If all required parameters are set and output_type = ‘array’ ,the function will return</p>
<ol class="arabic simple">
<li><p>a numpy array of the detected image</p></li>
<li><dl class="simple">
<dt>an array of dictionaries, with each dictionary corresponding to the objects</dt><dd><dl class="simple">
<dt>detected in the image. Each dictionary contains the following property:</dt><dd><ul class="simple">
<li><p>name (string)</p></li>
<li><p>percentage_probability (float)</p></li>
<li><p>box_points (list of x1,y1,x2 and y2 coordinates)</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</li>
</ol>
</dd>
</dl>
<p>“””
returned_image, detections = detector.detectObjectsFromImage(input_image=”image.jpg”, output_type=”array”, minimum_percentage_probability=30)</p>
<dl>
<dt>“””</dt><dd><dl>
<dt>If extract_detected_objects = True and ‘output_image_path’ is set to a file path you want</dt><dd><p>the detected image to be saved, the function will return:
1. an array of dictionaries, with each dictionary corresponding to the objects</p>
<blockquote>
<div><p>detected in the image. Each dictionary contains the following property:
* name (string)
* percentage_probability (float)
* box_points (list of x1,y1,x2 and y2 coordinates)</p>
</div></blockquote>
<ol class="arabic simple" start="2">
<li><p>an array of string paths to the image of each object extracted from the image</p></li>
</ol>
</dd>
</dl>
</dd>
</dl>
<p>“””
detections, extracted_objects = detector.detectObjectsFromImage(input_image=”image.jpg”, output_image_path=”imagenew.jpg”, extract_detected_objects=True, minimum_percentage_probability=30)</p>
<dl class="simple">
<dt>“””</dt><dd><dl class="simple">
<dt>If extract_detected_objects = True and output_type = ‘array’, the the function will return:</dt><dd><ol class="arabic simple">
<li><p>a numpy array of the detected image</p></li>
<li><dl class="simple">
<dt>an array of dictionaries, with each dictionary corresponding to the objects</dt><dd><p>detected in the image. Each dictionary contains the following property:
* name (string)
* percentage_probability (float)
* box_points (list of x1,y1,x2 and y2 coordinates)</p>
</dd>
</dl>
</li>
<li><p>an array of numpy arrays of each object detected in the image</p></li>
</ol>
</dd>
</dl>
</dd>
</dl>
<p>“””
returned_image, detections, extracted_objects = detector.detectObjectsFromImage(input_image=”image.jpg”, output_type=”array”, extract_detected_objects=True, minimum_percentage_probability=30)</p>
</div></blockquote>
</div></blockquote>
<ul>
<li><p><strong>.CustomObjects()</strong> , This function is used when you want to detect only a selected number of objects. It returns a dictionary of objects and their True or False values. To detect selected objects in an image, you will have to use the dictionary returned by the this function with the <strong>detectCustomObjectsFromImage()</strong> function. Find the details in the comment and code sample below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">There are 80 possible objects that you can detect with the</span>
<span class="sd">ObjectDetection class, and they are as seen below.</span>

<span class="sd">    person,   bicycle,   car,   motorcycle,   airplane,</span>
<span class="sd">    bus,   train,   truck,   boat,   traffic light,   fire hydrant,   stop_sign,</span>
<span class="sd">    parking meter,   bench,   bird,   cat,   dog,   horse,   sheep,   cow,   elephant,   bear,   zebra,</span>
<span class="sd">    giraffe,   backpack,   umbrella,   handbag,   tie,   suitcase,   frisbee,   skis,   snowboard,</span>
<span class="sd">    sports ball,   kite,   baseball bat,   baseball glove,   skateboard,   surfboard,   tennis racket,</span>
<span class="sd">    bottle,   wine glass,   cup,   fork,   knife,   spoon,   bowl,   banana,   apple,   sandwich,   orange,</span>
<span class="sd">    broccoli,   carrot,   hot dog,   pizza,   donot,   cake,   chair,   couch,   potted plant,   bed,</span>
<span class="sd">    dining table,   toilet,   tv,   laptop,   mouse,   remote,   keyboard,   cell phone,   microwave,</span>
<span class="sd">    oven,   toaster,   sink,   refrigerator,   book,   clock,   vase,   scissors,   teddy bear,   hair dryer,</span>
<span class="sd">    toothbrush.</span>

<span class="sd">To detect only some of the objects above, you will need to call the CustomObjects function and set the name of the</span>
<span class="sd">object(s) yiu want to detect to through. The rest are False by default. In below example, we detected only chose detect only person and dog.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">custom</span> <span class="o">=</span> <span class="n">detector</span><span class="o">.</span><span class="n">CustomObjects</span><span class="p">(</span><span class="n">person</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dog</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><strong>.detectCustomObjectsFromImage()</strong>, This function have all the parameters and returns all the values the <strong>detectObjectsFromImage()</strong> functions does but a slight difference. This function let detect only selected objects in an image. Unlike the normal <strong>detectObjectsFromImage()</strong> function, this needs an extra parameter which is “custom_object” which accepts the dictionary returned by the <strong>CustomObjects()</strong> function. In the sample below, we set the detection funtion to report only detections on persons and dogs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">custom</span> <span class="o">=</span> <span class="n">detector</span><span class="o">.</span><span class="n">CustomObjects</span><span class="p">(</span><span class="n">person</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dog</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">detections</span> <span class="o">=</span> <span class="n">detector</span><span class="o">.</span><span class="n">detectCustomObjectsFromImage</span><span class="p">(</span> <span class="n">custom_objects</span><span class="o">=</span><span class="n">custom</span><span class="p">,</span> <span class="n">input_image</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">execution_path</span> <span class="p">,</span> <span class="s2">&quot;image3.jpg&quot;</span><span class="p">),</span> <span class="n">output_image_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">execution_path</span> <span class="p">,</span> <span class="s2">&quot;image3new-custom.jpg&quot;</span><span class="p">),</span> <span class="n">minimum_percentage_probability</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
<p><strong>Sample Image Object Detection code</strong></p>
<p>Find below a code sample for detecting objects in an image:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">imageai.Detection</span> <span class="kn">import</span> <span class="n">ObjectDetection</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">execution_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>

<span class="n">detector</span> <span class="o">=</span> <span class="n">ObjectDetection</span><span class="p">()</span>
<span class="n">detector</span><span class="o">.</span><span class="n">setModelTypeAsYOLOv3</span><span class="p">()</span>
<span class="n">detector</span><span class="o">.</span><span class="n">setModelPath</span><span class="p">(</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">execution_path</span> <span class="p">,</span> <span class="s2">&quot;yolo.h5&quot;</span><span class="p">))</span>
<span class="n">detector</span><span class="o">.</span><span class="n">loadModel</span><span class="p">()</span>
<span class="n">detections</span> <span class="o">=</span> <span class="n">detector</span><span class="o">.</span><span class="n">detectObjectsFromImage</span><span class="p">(</span><span class="n">input_image</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">execution_path</span> <span class="p">,</span> <span class="s2">&quot;image.jpg&quot;</span><span class="p">),</span> <span class="n">output_image_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">execution_path</span> <span class="p">,</span> <span class="s2">&quot;imagenew.jpg&quot;</span><span class="p">),</span> <span class="n">minimum_percentage_probability</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

<span class="k">for</span> <span class="n">eachObject</span> <span class="ow">in</span> <span class="n">detections</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">eachObject</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="p">,</span> <span class="s2">&quot; : &quot;</span><span class="p">,</span> <span class="n">eachObject</span><span class="p">[</span><span class="s2">&quot;percentage_probability&quot;</span><span class="p">],</span> <span class="s2">&quot; : &quot;</span><span class="p">,</span> <span class="n">eachObject</span><span class="p">[</span><span class="s2">&quot;box_points&quot;</span><span class="p">]</span> <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--------------------------------&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="toctree-wrapper compound">
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../video/index.html" class="btn btn-neutral float-right" title="Video and Live-Feed Detection and Analysis" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../prediction/index.html" class="btn btn-neutral float-left" title="Prediction Classes" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2019, Moses Olafenwa and John Olafenwa

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>